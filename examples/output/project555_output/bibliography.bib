@book{boucheronConcentrationInequalitiesNonasymptotic2016,
  title = {Concentration {{Inequalities}}: {{A Nonasymptotic Theory}} of {{Independence}}},
  shorttitle = {Concentration {{Inequalities}}},
  author = {Boucheron, Stephane and Lugosi, Gabor and Massart, Pascal},
  year = {2016},
  month = feb,
  publisher = {{Oxford University Press}},
  address = {{Oxford New York, NY}},
  isbn = {978-0-19-876765-7},
  langid = {english},
  file = {/Users/matthewscott/Zotero/storage/LYEW2D4J/3557008720543446793concentration_inequalities.pdf}
}

@inproceedings{maurerConcentrationInequalitiesSubGaussian2021,
  title = {Concentration Inequalities under Sub-{{Gaussian}} and Sub-Exponential Conditions},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Maurer, Andreas and Pontil, Massimiliano},
  year = {2021},
  volume = {34},
  pages = {7588--7597},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2023-03-20},
  abstract = {We prove analogues of the popular bounded difference inequality (also called McDiarmid's inequality) for functions of independent random variables under sub-gaussian and sub-exponential conditions. Applied to vector-valued concentration and the method of Rademacher complexities these inequalities allow an easy extension of uniform convergence results for PCA and linear regression to the case potentially unbounded input- and output variables.},
  file = {/Users/matthewscott/Zotero/storage/92F9HH7R/Maurer_Pontil_2021_Concentration inequalities under sub-Gaussian and sub-exponential conditions.pdf}
}

@book{wainwrightHighDimensionalStatisticsNonAsymptotic2019,
  title = {High-{{Dimensional Statistics}}: {{A Non-Asymptotic Viewpoint}}},
  shorttitle = {High-{{Dimensional Statistics}}},
  author = {Wainwright, Martin J.},
  year = {2019},
  month = feb,
  publisher = {{Cambridge University Press}},
  address = {{Cambridge ; New York, NY}},
  abstract = {Recent years have witnessed an explosion in the volume and variety of data collected in all scientific disciplines and industrial settings. Such massive data sets present a number of challenges to researchers in statistics and machine learning. This book provides a self-contained introduction to the area of high-dimensional statistics, aimed at the first-year graduate level. It includes chapters that are focused on core methodology and theory - including tail bounds, concentration inequalities, uniform laws and empirical process, and random matrices - as well as chapters devoted to in-depth exploration of particular model classes - including sparse linear models, matrix models with rank constraints, graphical models, and various types of non-parametric models. With hundreds of worked examples and exercises, this text is intended both for courses and for self-study by graduate students and researchers in statistics, machine learning, and related fields who must understand, apply, and adapt modern statistical methods suited to large-scale data.},
  isbn = {978-1-108-49802-9},
  langid = {english},
  file = {/Users/matthewscott/Zotero/storage/WQNVDKUV/Martin J. Wainwright - High-Dimensional Statistics A Non-Asymptotic Viewpoint-Cambridge University Press ( 2019).pdf}
}
